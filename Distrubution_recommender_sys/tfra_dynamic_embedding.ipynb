{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-07 18:21:24.927 WARN [component.py:675] TrainingComponent_logger - \u0001\u0001chart将从本地获取，本地路径：/app/arsenal_magic/charts/tensorflow-launcher-0.0.10.tgz\n",
      "2021-05-07 18:21:25.021 INFO [helm_util.py:154] helm_logger - \u0001\u0001install chart start !\n",
      "2021-05-07 18:21:31.341 INFO [helm_util.py:160] helm_logger - \u0001\u0001install chart success, release_name: \u001b[1;38;5;21mwishing-zebra\u001b[0m \n",
      "2021-05-07 18:21:31.342 INFO [training.py:189] TrainingComponent_logger - \u0001\u0001Training Job[train] is running, Output: /models/tensorflow24/train\n",
      "2021-05-07 18:21:32.362 INFO [workflow.py:522] WorkFlow_logger - \u0001\u0001也可以通过点击下方链接，查看es日志\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href=\"http://log-elk.weizhipin.com/s/arsenal_pro/app/infra#/logs/stream?_g=()&flyoutOptions=(flyoutId:!n,flyoutVisibility:hidden,surroundingLogsId:!n)&logPosition=(position:(tiebreaker:0,time:0),streamLive:!f)&streamLive:!f)&logFilter=(expression:'kubernetes.labels.helm_release:%22wishing-zebra%22%20and%20kubernetes.labels.EXPERIMENT_NAME:%22tensorflow24%22',kind:kuery)&from=now-1h&to=now&refresh=10s&theme=light&kiosk=tv\" target=\"_blank\">查看wishing-zebra日志</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m8;5;144mchecking pod status ... 2021-05-07 18:21:57.718 WARN [helm_util.py:440] helm_logger - \u0001\u0001当前组件release_name：\u001b[1;38;5;21mwishing-zebra\u001b[0m为\u001b[1;38;5;21mpending\u001b[0m状态, 如果此状态延续7200秒，任务将会被删除，如果想延长此时间可用 --pending_wait_time 200 延长至200秒，最长不超过 --pending_wait_time 2h （2小时），当前的异常具体原因为:\n",
      "\u001b[1;38;5;21m异常类型：ContainersReady，异常描述：containers with unready status: [tensorflow]\n",
      "异常类型：Ready，异常描述：containers with unready status: [tensorflow]\u001b[0m \n",
      "\n",
      "\u001b[0m8;5;11mchecking pod status ...  2021-05-07 18:30:45.674 INFO [helm_util.py:467] helm_logger - \u0001\u0001\u001b[1;38;5;21mpod启动成功，下面为调度到机器的信息：\n",
      "pod_name: wb-cuidongdong-m-tra-wishing-zebra-tfjob-ps-0, 所在主机ip：172.24.16.117，所在主机名：dx-k8sarsenalwork-91\n",
      "pod_name: wb-cuidongdong-m-tra-wishing-zebra-tfjob-ps-1, 所在主机ip：172.24.16.126，所在主机名：dx-k8sarsenalwork-112\n",
      "pod_name: wb-cuidongdong-m-tra-wishing-zebra-tfjob-worker-0, 所在主机ip：172.24.16.96，所在主机名：dx-k8sarsenalwork-63\n",
      "pod_name: wb-cuidongdong-m-tra-wishing-zebra-tfjob-worker-1, 所在主机ip：172.24.16.117，所在主机名：dx-k8sarsenalwork-91\u001b[0m \n",
      "\u001b[1m\u0001\u0001查看日志：'%model_training logs'                    \u001b[0m \n",
      "\u001b[1m\u0001\u0001安全等待任务完成：'%model_training await_done'\u001b[0m  \n",
      "\u001b[1m\u0001\u0001不再等待，立即终止程序：'%model_training await_done --force'\u001b[0m  \n"
     ]
    }
   ],
   "source": [
    "%%model_training submit\n",
    "-f tensorflow\n",
    "--data_input=/dataset/example/\n",
    "--parallel_mode=1\n",
    "--work_dir=/privatecode/tensorflow24/\n",
    "--pss=2\n",
    "--ps_img=harbor.weizhipin.com/arsenal_notebook/tfra:0.0.1\n",
    "--ps_cmd=python\n",
    "--ps_args=tfra-movielens-1m.py\n",
    "--ps_cpu=4\n",
    "--ps_memory=8Gi\n",
    "--workers=2\n",
    "--worker_img=harbor.weizhipin.com/arsenal_notebook/tfra:0.0.1\n",
    "--worker_cmd=python\n",
    "--worker_args=tfra-movielens-1m.py\n",
    "--worker_cpu=2\n",
    "--worker_memory=16Gi\n",
    "--disable_data_save_mode\n",
    "--disable_model_version\n",
    "--pending_wait_time 2h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;21m**********************************************************************************\u001b[0m\n",
      "\u001b[1;38;5;21m*****************如未登陆请使用账号：arsenal_read 密码：arsenal_read *****************\u001b[0m\n",
      "\u001b[1;38;5;21m**********************************************************************************\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://log-elk.weizhipin.com/s/arsenal_pro/app/infra#/logs/stream?_g=()&flyoutOptions=(flyoutId:KsAkhW8BW_AwBUnZiELf,flyoutVisibility:hidden,surroundingLogsId:!n)&logFilter=(expression:'kubernetes.pod.name:%22wb-cuidongdong-m-tra-wishing-zebra-tfjob-ps-0%22%20',kind:kuery)&logPosition=(position:(tiebreaker:0,time:0),streamLive:!f&refresh=120s)&streamLive:!f)\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fbca0d975c0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%model_training logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-07 19:51:25.346 INFO [helm_util.py:198] helm_logger - \u0001\u0001start to uninstall release: \u001b[1;38;5;21mwishing-zebra\u001b[0m\n",
      "2021-05-07 19:51:25.561 INFO [helm_util.py:200] helm_logger - \u0001\u0001release \u001b[1;38;5;21mwishing-zebra\u001b[0m uninstall completely!\n",
      "2021-05-07 19:51:25.564 WARN [component.py:675] OssBuckteDeleter_logger - \u0001\u0001chart将从本地获取，本地路径：/app/arsenal_magic/charts/minio-bucket-deleter-0.1.3.tgz\n",
      "2021-05-07 19:51:25.642 INFO [helm_util.py:154] helm_logger - \u0001\u0001install chart start !\n",
      "2021-05-07 19:51:27.997 INFO [helm_util.py:160] helm_logger - \u0001\u0001install chart success, release_name: \u001b[1;38;5;21mbrazen-worm\u001b[0m \n",
      "\u001b[0m8;5;180mpod is Running ... 2021-05-07 19:51:35.397 INFO [helm_util.py:198] helm_logger - \u0001\u0001start to uninstall release: \u001b[1;38;5;21mbrazen-worm\u001b[0m\n",
      "2021-05-07 19:51:36.614 INFO [helm_util.py:200] helm_logger - \u0001\u0001release \u001b[1;38;5;21mbrazen-worm\u001b[0m uninstall completely!\n",
      "2021-05-07 19:51:36.615 ERROR [workflow.py:686] WorkFlow_logger - \u0001\u0001\u001b[1;38;5;160m组件TrainingComponent wait pod ready 失败，release_name：wishing-zebra，可尝试通过上方深色标记日志进行debug，如需帮助，请将后面的完整信息复制给运维人员: {\n",
      "  \"exp_name\": \"tensorflow24\",\n",
      "  \"release_name\": \"wishing-zebra\",\n",
      "  \"comp_name\": \"TrainingComponent\",\n",
      "  \"arg_map\": {\n",
      "    \"command\": \"await_done\",\n",
      "    \"debug\": false,\n",
      "    \"parallel_mode\": 0,\n",
      "    \"work_dir\": \"/\",\n",
      "    \"pss\": 0,\n",
      "    \"ps_cpu\": \"0.5\",\n",
      "    \"ps_memory\": \"100Mi\",\n",
      "    \"ps_gpu\": 0,\n",
      "    \"workers\": 1,\n",
      "    \"worker_cpu\": \"0.5\",\n",
      "    \"worker_memory\": \"100Mi\",\n",
      "    \"worker_gpu\": 0,\n",
      "    \"dry_run\": false,\n",
      "    \"force\": false,\n",
      "    \"jupyter\": false,\n",
      "    \"disable_data_save_mode\": false,\n",
      "    \"log_first\": false,\n",
      "    \"parallel\": false,\n",
      "    \"disable_model_version\": false,\n",
      "    \"magic_type\": \"magic\",\n",
      "    \"magic_name\": \"model_training\",\n",
      "    \"magic_func_name\": \"model_training_func\",\n",
      "    \"comp_type\": \"MODEL_TRAINING\",\n",
      "    \"comp_type_code\": 4\n",
      "  }\n",
      "}\u001b[0m \n",
      "TrainingComponent.await_done has executed, TrainingComponent is \u001b[1;38;5;21mshutdown now\u001b[0m\n",
      "2021-05-07 19:51:36.620 ERROR [workflow.py:57] workflow_logger - \n",
      "\u001b[1m注意，程序执行出现异常，在ide中：magic形式执行会显示异常简述，函数执行会抛出表层异常；在周期性作业中：magic和函数都会显示详细的异常栈。\n",
      "具体错误描述为：\u001b[1;38;5;160mpod已不存在，资源可能已被自动回收\u001b[0m  \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%model_training await_done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow_recommenders_addons/utils/ensure_tf_install.py:66: UserWarning: Tensorflow Recommenders Addons supports using Python ops for all Tensorflow versions above or equal to 2.4.1 and strictly below 2.4.1 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.2.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the Recommenders Addons's version. \n",
      "You can find the compatibility matrix in Recommenders Addon's readme:\n",
      "https://github.com/tensorflow/recommenders-addons\n",
      "  UserWarning,\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow_recommenders_addons/utils/resource_loader.py:97: UserWarning: You are currently using TensorFlow 2.2.0 and trying to load a custom op (dynamic_embedding/core/_cuckoo_hashtable_ops.so).\n",
      "TensorFlow Recommenders Addons has compiled its custom ops against TensorFlow 2.4.1, and there are no compatibility guarantees between the two versions. \n",
      "This means that you might get 'Symbol not found' when loading the custom op, or other kind of low-level errors.\n",
      " If you do, do not file an issue on Github. This is a known limitation.\n",
      "\n",
      "You can also change the TensorFlow version installed on your system. You would need a TensorFlow version equal to 2.4.1. \n",
      "Note that nightly versions of TensorFlow, as well as non-pip TensorFlow like `conda install tensorflow` or compiled from source are not supported.\n",
      "\n",
      "The last solution is to compile the TensorFlow Recommenders-Addons with the TensorFlow installed on your system. To do that, refer to the readme: https://github.com/tensorflow/recommenders-addons\n",
      "  UserWarning,\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "/usr/local/lib/python3.6/dist-packages/tensorflow_recommenders_addons/dynamic_embedding/core/_cuckoo_hashtable_ops.so: undefined symbol: _ZNK10tensorflow8OpKernel11TraceStringERKNS_15OpKernelContextEb",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-dd021dd74486>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_recommenders_addons\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfra\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable_v2_behavior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_recommenders_addons/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"v0.1.0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_recommenders_addons\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdynamic_embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_recommenders_addons\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0membedding_variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_recommenders_addons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mregister_all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_recommenders_addons/dynamic_embedding/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\"\"\"Export dynamic_embedding APIs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m from tensorflow_recommenders_addons.dynamic_embedding.python.ops.cuckoo_hashtable_ops import (\n\u001b[0m\u001b[1;32m     18\u001b[0m     CuckooHashTable,)\n\u001b[1;32m     19\u001b[0m from tensorflow_recommenders_addons.dynamic_embedding.python.ops.dynamic_embedding_optimizer import (\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_recommenders_addons/dynamic_embedding/python/ops/cuckoo_hashtable_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m cuckoo_hashtable_ops = LazySO(\n\u001b[0;32m---> 31\u001b[0;31m     \"dynamic_embedding/core/_cuckoo_hashtable_ops.so\").ops\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_recommenders_addons/utils/resource_loader.py\u001b[0m in \u001b[0;36mops\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ops\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay_warning_if_incompatible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_op_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_path_to_datafile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelative_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/load_library.py\u001b[0m in \u001b[0;36mload_op_library\u001b[0;34m(library_filename)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \"\"\"\n\u001b[1;32m     57\u001b[0m   \u001b[0mlib_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpy_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_LoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibrary_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     wrappers = _pywrap_python_op_gen.GetPythonWrappers(\n\u001b[1;32m     60\u001b[0m         py_tf.TF_GetOpList(lib_handle))\n",
      "\u001b[0;31mNotFoundError\u001b[0m: /usr/local/lib/python3.6/dist-packages/tensorflow_recommenders_addons/dynamic_embedding/core/_cuckoo_hashtable_ops.so: undefined symbol: _ZNK10tensorflow8OpKernel11TraceStringERKNS_15OpKernelContextEb"
     ]
    }
   ],
   "source": [
    "# import os, sys, json\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.layers import Dense\n",
    "# import tensorflow_datasets as tfds\n",
    "# import tensorflow_recommenders_addons as tfra\n",
    "\n",
    "\n",
    "# tf.compat.v1.disable_v2_behavior()\n",
    "# tf.compat.v1.disable_eager_execution()\n",
    "# tf.compat.v1.disable_resource_variables()\n",
    "\n",
    "# # flags = tf.compat.v1.app.flags\n",
    "# # FLAGS = flags.FLAGS\n",
    "# # flags.DEFINE_string(\n",
    "# #     'ps_list', \"localhost:2220, localhost:2221\",\n",
    "# #     'ps_list: to be a comma seperated string, '\n",
    "# #     'like \"localhost:2220, localhost:2220\"')\n",
    "# # flags.DEFINE_string(\n",
    "# #     'worker_list', \"localhost:2230\",\n",
    "# #     'worker_list: to be a comma seperated string, '\n",
    "# #     'like \"localhost:2230, localhost:2231\"')\n",
    "# # flags.DEFINE_string('task_mode', \"worker\", 'runninig_mode: ps or worker.')\n",
    "# # flags.DEFINE_integer('task_id', 0, 'task_id: used for allocating samples.')\n",
    "# # flags.DEFINE_bool('is_chief', False, ''\n",
    "# #                   ': If true, will run init_op and save/restore.')\n",
    "\n",
    "# # os.environ[\"TF_CONFIG\"] = json.dumps({\n",
    "# #     \"cluster\": {\n",
    "# #         \"worker\": [\"localhost:9901\", \"localhost:9902\", \"localhost:9903\"],\n",
    "# #         \"ps\": [\"localhost:9904\"]\n",
    "# #     },\n",
    "# #    \"task\": {\"type\": \"worker\", \"index\": 1}\n",
    "# # })\n",
    "\n",
    "# tf_config = json.loads(os.environ['TF_CONFIG'])\n",
    "\n",
    "# ps_list = tf_config[\"cluster\"][\"ps\"]\n",
    "# worker_list = tf_config[\"cluster\"][\"worker\"]\n",
    "# task_mode = tf_config[\"task\"][\"type\"]\n",
    "# task_id = tf_config[\"task\"][\"index\"]\n",
    "\n",
    "# if task_mode==\"worker\" and task_id == 0:\n",
    "#     is_chief= True\n",
    "# else:\n",
    "#     is_chief= False\n",
    "\n",
    "\n",
    "# class Trainer():\n",
    "\n",
    "#   def __init__(self, worker_id, worker_num, ps_num, batch_size, ckpt_dir=None):\n",
    "#     self.embedding_size = 32\n",
    "#     self.worker_id = worker_id\n",
    "#     self.worker_num = worker_num\n",
    "#     self.batch_size = batch_size\n",
    "#     self.devices = [\n",
    "#         \"/job:ps/replica:0/task:{}\".format(idx) for idx in range(ps_num)\n",
    "#     ]\n",
    "#     self.ckpt_dir = ckpt_dir\n",
    "#     if self.ckpt_dir:\n",
    "#       os.makedirs(os.path.split(self.ckpt_dir)[0], exist_ok=True)\n",
    "\n",
    "#   def read_batch(self):\n",
    "#     split_size = int(100 / self.worker_num)\n",
    "    \n",
    "#     split_start = split_size * self.worker_id\n",
    "    \n",
    "#     split = 'train[{}%:{}%]'.format(split_start, split_start + split_size - 1)\n",
    "#     print(\"dataset split, worker{}: {}\".format(self.worker_id, split))\n",
    "    \n",
    "#     ratings = tfds.load(\"movielens/1m-ratings\", split=split,data_dir=\"/dataset\")\n",
    "#     ratings = ratings.map(\n",
    "#         lambda x: {\n",
    "#             \"movie_id\": tf.strings.to_number(x[\"movie_id\"], tf.int64),\n",
    "#             \"user_id\": tf.strings.to_number(x[\"user_id\"], tf.int64),\n",
    "#             \"user_rating\": x[\"user_rating\"]\n",
    "#         })\n",
    "#     shuffled = ratings.shuffle(1_000_000,\n",
    "#                                seed=2021,\n",
    "#                                reshuffle_each_iteration=False)\n",
    "#     dataset_train = shuffled.batch(self.batch_size)\n",
    "#     train_iter = tf.compat.v1.data.make_initializable_iterator(dataset_train)\n",
    "#     return train_iter\n",
    "\n",
    "#   def build_graph(self, batch):\n",
    "#     movie_id = batch[\"movie_id\"]\n",
    "#     user_id = batch[\"user_id\"]\n",
    "#     rating = batch[\"user_rating\"]\n",
    "\n",
    "#     d0 = Dense(256,\n",
    "#                activation='relu',\n",
    "#                kernel_initializer=tf.keras.initializers.RandomNormal(0.0, 0.1),\n",
    "#                bias_initializer=tf.keras.initializers.RandomNormal(0.0, 0.1))\n",
    "#     d1 = Dense(64,\n",
    "#                activation='relu',\n",
    "#                kernel_initializer=tf.keras.initializers.RandomNormal(0.0, 0.1),\n",
    "#                bias_initializer=tf.keras.initializers.RandomNormal(0.0, 0.1))\n",
    "#     d2 = Dense(1,\n",
    "#                kernel_initializer=tf.keras.initializers.RandomNormal(0.0, 0.1),\n",
    "#                bias_initializer=tf.keras.initializers.RandomNormal(0.0, 0.1))\n",
    "#     user_embeddings = tfra.dynamic_embedding.get_variable(\n",
    "#         name=\"user_dynamic_embeddings\",\n",
    "#         dim=self.embedding_size,\n",
    "#         devices=self.devices,\n",
    "#         initializer=tf.keras.initializers.RandomNormal(-1, 1))\n",
    "#     movie_embeddings = tfra.dynamic_embedding.get_variable(\n",
    "#         name=\"moive_dynamic_embeddings\",\n",
    "#         dim=self.embedding_size,\n",
    "#         devices=self.devices,\n",
    "#         initializer=tf.keras.initializers.RandomNormal(-1, 1))\n",
    "\n",
    "#     user_id_val, user_id_idx = tf.unique(user_id)\n",
    "#     user_id_weights, user_id_trainable_wrapper = tfra.dynamic_embedding.embedding_lookup(\n",
    "#         params=user_embeddings,\n",
    "#         ids=user_id_val,\n",
    "#         name=\"user-id-weights\",\n",
    "#         return_trainable=True)\n",
    "#     user_id_weights = tf.gather(user_id_weights, user_id_idx)\n",
    "\n",
    "#     movie_id_val, movie_id_idx = tf.unique(movie_id)\n",
    "#     movie_id_weights, movie_id_trainable_wrapper = tfra.dynamic_embedding.embedding_lookup(\n",
    "#         params=movie_embeddings,\n",
    "#         ids=movie_id_val,\n",
    "#         name=\"movie-id-weights\",\n",
    "#         return_trainable=True)\n",
    "#     movie_id_weights = tf.gather(movie_id_weights, movie_id_idx)\n",
    "\n",
    "#     embeddings = tf.concat([user_id_weights, movie_id_weights], axis=1)\n",
    "#     dnn = d0(embeddings)\n",
    "#     dnn = d1(dnn)\n",
    "#     dnn = d2(dnn)\n",
    "#     predict = tf.reshape(dnn, shape=[-1])\n",
    "#     loss = tf.keras.losses.MeanSquaredError()(rating, predict)\n",
    "#     optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=0.001)\n",
    "#     optimizer = tfra.dynamic_embedding.DynamicEmbeddingOptimizer(optimizer)\n",
    "#     update = optimizer.minimize(\n",
    "#         loss, global_step=tf.compat.v1.train.get_or_create_global_step())\n",
    "#     return {\n",
    "#         \"update\": update,\n",
    "#         \"predict\": predict,\n",
    "#         \"loss\": loss,\n",
    "#         \"size\": user_embeddings.size(),\n",
    "#     }\n",
    "\n",
    "\n",
    "# def start_worker(worker_id, config):\n",
    "#   print(\"worker config\", config)\n",
    "\n",
    "#   num_ps_tasks = len(ps_list)\n",
    "#   num_worker_tasks = len(worker_list)\n",
    "#   sess_config = tf.compat.v1.ConfigProto()\n",
    "#   sess_config.intra_op_parallelism_threads = 1\n",
    "#   sess_config.inter_op_parallelism_threads = 1\n",
    "#   cluster = tf.train.ClusterSpec(config['cluster'])\n",
    "#   server = tf.distribute.Server(cluster,\n",
    "#                                 protocol=\"grpc\",\n",
    "#                                 job_name=\"worker\",\n",
    "#                                 task_index=worker_id,\n",
    "#                                 config=sess_config)\n",
    "#   with tf.compat.v1.device(\"/job:worker/replica:0/task:{}\".format(worker_id)):\n",
    "#     trainer = Trainer(worker_id=worker_id,\n",
    "#                       worker_num=num_worker_tasks,\n",
    "#                       ps_num=num_ps_tasks,\n",
    "#                       batch_size=64,\n",
    "#                       ckpt_dir=None)\n",
    "#     train_iter = trainer.read_batch()\n",
    "#     train_data = train_iter.get_next()\n",
    "\n",
    "#   device_setter = tf.compat.v1.train.replica_device_setter(\n",
    "#       ps_tasks=num_ps_tasks,\n",
    "#       worker_device=\"/job:worker/replica:0/task:{}\".format(worker_id),\n",
    "#       ps_device=\"/job:ps\")\n",
    "\n",
    "#   with tf.compat.v1.device(device_setter):\n",
    "#     outputs = trainer.build_graph(train_data)\n",
    "\n",
    "#   with tf.compat.v1.train.MonitoredTrainingSession(\n",
    "#       master=server.target,\n",
    "#       is_chief=is_chief,\n",
    "#       checkpoint_dir=trainer.ckpt_dir if is_chief else None,\n",
    "#       config=sess_config,\n",
    "#   ) as sess:\n",
    "#     sess.run([train_iter.initializer])\n",
    "\n",
    "#     step = 0\n",
    "#     while True:\n",
    "#       step += 1\n",
    "#       try:\n",
    "#         _, _loss, _pred = sess.run(\n",
    "#             [outputs[\"update\"], outputs[\"loss\"], outputs[\"predict\"]])\n",
    "\n",
    "#         _size = sess.run(outputs[\"size\"])\n",
    "#         if step % 100 == 0:\n",
    "#           print(\"[worker{}]step{}:\\tloss={:.4f}\\t size={}\".format(\n",
    "#               worker_id, step, float(_loss), _size))\n",
    "#       except tf.errors.OutOfRangeError:\n",
    "#         print(\"[worker{}]no more data!\".format(worker_id))\n",
    "#         break\n",
    "\n",
    "\n",
    "# def start_ps(task_id, config):\n",
    "#   print(\"ps config\", config)\n",
    "#   cluster = tf.train.ClusterSpec(config[\"cluster\"])\n",
    "\n",
    "#   sess_config = tf.compat.v1.ConfigProto()\n",
    "#   sess_config.intra_op_parallelism_threads = 1\n",
    "#   sess_config.inter_op_parallelism_threads = 1\n",
    "#   server = tf.distribute.Server(cluster,\n",
    "#                                 config=sess_config,\n",
    "#                                 protocol='grpc',\n",
    "#                                 job_name=\"ps\",\n",
    "#                                 task_index=task_id)\n",
    "#   server.join()\n",
    "\n",
    "\n",
    "# def main(argv):\n",
    "\n",
    "\n",
    "\n",
    "#   print('ps_list: ', ps_list)\n",
    "#   print('worker_list: ', worker_list)\n",
    "\n",
    "#   if task_mode == 'ps':\n",
    "#     start_ps(task_id, tf_config)\n",
    "#   elif task_mode == 'worker':\n",
    "#     start_worker(task_id, tf_config)\n",
    "#   else:\n",
    "#     print('invalid task_mode. Options include \"ps\" and \"worker\".')\n",
    "#     sys.exit(1)\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#   tf.compat.v1.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
